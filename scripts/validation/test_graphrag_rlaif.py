"""
Test suite for Enhanced GraphRAG and RLAIF Evaluator.

This script demonstrates the usage and validates the functionality of:
1. Enhanced GraphRAG with LLM-based extraction and multi-hop reasoning
2. RLAIF Evaluation System with comprehensive feedback

Usage:
    python scripts/test_graphrag_rlaif.py
"""

import asyncio
import logging
from typing import Dict, Any

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ==================== Mock LLM Client ====================

class MockLLMClient:
    """Mock LLM client for testing."""

    async def generate(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 1000,
    ) -> str:
        """Generate mock response based on prompt type."""

        # Entity extraction
        if "æå–å…³é”®å®ä½“" in prompt or "extract entities" in prompt.lower():
            return """{
  "entities": [
    {
      "name": "å¹´è´¹å¤ªè´µ",
      "type": "objection",
      "properties": {
        "description": "å®¢æˆ·å¯¹å¹´è´¹ä»·æ ¼çš„å¼‚è®®",
        "context": "å®¢æˆ·è®¤ä¸º1000å…ƒå¹´è´¹è¿‡é«˜"
      }
    },
    {
      "name": "æ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹",
      "type": "response",
      "properties": {
        "description": "é€šè¿‡æ¶ˆè´¹è¾¾æ ‡å¯ä»¥å…é™¤å¹´è´¹",
        "context": "å¹´æ¶ˆè´¹æ»¡10ä¸‡å³å¯å…å¹´è´¹"
      }
    },
    {
      "name": "æœºåœºè´µå®¾å…",
      "type": "benefit",
      "properties": {
        "description": "æœºåœºè´µå®¾å…æƒç›Š",
        "context": "å¯äº«å—å…¨çƒæœºåœºè´µå®¾å…æœåŠ¡"
      }
    },
    {
      "name": "ç§¯åˆ†è¿”ç°",
      "type": "benefit",
      "properties": {
        "description": "æ¶ˆè´¹ç§¯åˆ†è¿”ç°",
        "context": "æ¶ˆè´¹å¯è·å¾—ç§¯åˆ†å¹¶è¿”ç°"
      }
    },
    {
      "name": "ä»·å€¼è½¬åŒ–",
      "type": "technique",
      "properties": {
        "description": "å°†ä»·æ ¼è½¬åŒ–ä¸ºä»·å€¼çš„é”€å”®æŠ€å·§",
        "context": "å¼ºè°ƒæƒç›Šä»·å€¼è¶…è¿‡å¹´è´¹"
      }
    }
  ]
}"""

        # Relation extraction
        elif "è¯†åˆ«å®ä½“ä¹‹é—´çš„å…³ç³»" in prompt or "extract relations" in prompt.lower():
            return """{
  "relations": [
    {
      "source": "å¹´è´¹å¤ªè´µ",
      "target": "æ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹",
      "type": "addresses",
      "properties": {
        "confidence": 0.95,
        "evidence": "é”€å† ç”¨æ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹æ¥åº”å¯¹å¹´è´¹å¼‚è®®"
      }
    },
    {
      "source": "æ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹",
      "target": "æœºåœºè´µå®¾å…",
      "type": "provides_benefit",
      "properties": {
        "confidence": 0.90,
        "evidence": "å…å¹´è´¹åå¯äº«å—æœºåœºè´µå®¾å…æƒç›Š"
      }
    },
    {
      "source": "æ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹",
      "target": "ç§¯åˆ†è¿”ç°",
      "type": "provides_benefit",
      "properties": {
        "confidence": 0.90,
        "evidence": "å…å¹´è´¹åå¯äº«å—ç§¯åˆ†è¿”ç°"
      }
    },
    {
      "source": "æ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹",
      "target": "ä»·å€¼è½¬åŒ–",
      "type": "part_of",
      "properties": {
        "confidence": 0.85,
        "evidence": "è¿™æ˜¯ä»·å€¼è½¬åŒ–æŠ€å·§çš„ä¸€éƒ¨åˆ†"
      }
    }
  ]
}"""

        # Reward model scoring
        elif "å¯¹ä»¥ä¸‹é”€å”®å›åº”è¿›è¡Œè¯„åˆ†" in prompt:
            return """{
  "overall_score": 0.85,
  "dimension_scores": [
    {
      "dimension": "completeness",
      "score": 0.90,
      "reasoning": "å®Œæ•´å›ç­”äº†å®¢æˆ·çš„æ‰€æœ‰ç–‘é—®ï¼ŒåŒ…æ‹¬å¹´è´¹ã€æƒç›Šå’Œä»·å€¼",
      "evidence": ["æåˆ°äº†å¹´è´¹å‡å…æ”¿ç­–", "è¯´æ˜äº†æƒç›Šä»·å€¼", "ç»™å‡ºäº†å…·ä½“æ•°å­—"]
    },
    {
      "dimension": "relevance",
      "score": 0.88,
      "reasoning": "å›åº”åˆ‡ä¸­è¦å®³ï¼Œç›´æ¥è§£å†³äº†å®¢æˆ·çš„ä»·æ ¼é¡¾è™‘",
      "evidence": ["é’ˆå¯¹å¹´è´¹é—®é¢˜", "æä¾›äº†è§£å†³æ–¹æ¡ˆ"]
    },
    {
      "dimension": "compliance",
      "score": 0.95,
      "reasoning": "ç¬¦åˆåˆè§„è¦æ±‚ï¼Œå¦‚å®å‘ŠçŸ¥äº†è´¹ç”¨å’Œæƒç›Š",
      "evidence": ["æ˜ç¡®è¯´æ˜äº†å¹´è´¹é‡‘é¢", "å‡†ç¡®æè¿°äº†æƒç›Šå†…å®¹"]
    },
    {
      "dimension": "empathy",
      "score": 0.92,
      "reasoning": "é¦–å…ˆè¡¨è¾¾äº†ç†è§£ï¼Œå»ºç«‹äº†åŒç†å¿ƒ",
      "evidence": ["æˆ‘ç†è§£æ‚¨çš„é¡¾è™‘"]
    },
    {
      "dimension": "persuasiveness",
      "score": 0.85,
      "reasoning": "ç”¨å…·ä½“æ•°æ®å’Œæƒç›Šè¯´æ˜ä»·å€¼ï¼Œæœ‰è¯´æœåŠ›",
      "evidence": ["å¹´æ¶ˆè´¹æ»¡10ä¸‡", "ä»·å€¼è¶…è¿‡5000å…ƒ"]
    },
    {
      "dimension": "professionalism",
      "score": 0.88,
      "reasoning": "è¡¨è¾¾ä¸“ä¸šå¾—ä½“ï¼Œæ²¡æœ‰è¿‡åº¦æ¨é”€",
      "evidence": ["è¯­æ°”æ¸©å’Œ", "é€»è¾‘æ¸…æ™°"]
    },
    {
      "dimension": "clarity",
      "score": 0.90,
      "reasoning": "è¡¨è¾¾æ¸…æ™°ï¼Œæ˜“äºç†è§£",
      "evidence": ["ç»“æ„æ¸…æ™°", "ç”¨è¯å‡†ç¡®"]
    },
    {
      "dimension": "accuracy",
      "score": 0.95,
      "reasoning": "ä¿¡æ¯å‡†ç¡®ï¼Œæ•°æ®çœŸå®",
      "evidence": ["å¹´è´¹1000å…ƒ", "æ¶ˆè´¹æ»¡10ä¸‡å…å¹´è´¹"]
    }
  ],
  "strengths": ["åŒç†å¿ƒå¼º", "é€»è¾‘æ¸…æ™°", "æ•°æ®æ”¯æ’‘", "ä»·å€¼è½¬åŒ–åˆ°ä½"],
  "weaknesses": ["å¯ä»¥æ›´å…·ä½“è¯´æ˜æƒç›Šç»†èŠ‚", "å¯ä»¥è¡¥å……æˆåŠŸæ¡ˆä¾‹"],
  "suggestions": ["å»ºè®®è¡¥å……å…·ä½“çš„æƒç›Šä½¿ç”¨æ¡ˆä¾‹", "å¯ä»¥åˆ†äº«å…¶ä»–å®¢æˆ·çš„æˆåŠŸç»éªŒ"]
}"""

        # Pairwise comparison
        elif "æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªé”€å”®å›åº”" in prompt:
            return """{
  "preferred": "B",
  "confidence": 0.85,
  "reasoning": "å›åº”Båœ¨åŒç†å¿ƒå’Œè¯´æœåŠ›æ–¹é¢æ˜æ˜¾ä¼˜äºå›åº”Aã€‚Bé¦–å…ˆè®¤å¯äº†å®¢æˆ·çš„é¡¾è™‘ï¼Œç„¶åç”¨å…·ä½“çš„æƒç›Šæ¡ˆä¾‹è¯´æ˜ä»·å€¼ï¼Œé€»è¾‘æ¸…æ™°ä¸”æœ‰è¯´æœåŠ›ã€‚è€ŒAè™½ç„¶ä¹Ÿæåˆ°äº†å…å¹´è´¹ï¼Œä½†ç›´æ¥æ¨é”€æ˜¾å¾—ç”Ÿç¡¬ï¼Œç¼ºä¹åŒç†å¿ƒçš„å»ºç«‹ã€‚",
  "dimension_comparison": {
    "completeness": "B",
    "relevance": "tie",
    "compliance": "tie",
    "empathy": "B",
    "persuasiveness": "B",
    "professionalism": "B",
    "clarity": "tie",
    "accuracy": "tie"
  }
}"""

        # Process supervision
        elif "è¯„ä¼°é”€å”®äººå‘˜çš„æ€è€ƒè¿‡ç¨‹" in prompt:
            return """{
  "step_evaluations": [
    {
      "step_number": 1,
      "step_content": "è¯†åˆ«å¼‚è®®ç±»å‹ï¼šä»·æ ¼å¼‚è®®",
      "is_correct": true,
      "is_necessary": true,
      "feedback": "æ­£ç¡®è¯†åˆ«äº†å®¢æˆ·çš„ä»·æ ¼å¼‚è®®ï¼Œè¿™æ˜¯åº”å¯¹çš„åŸºç¡€",
      "score": 0.95
    },
    {
      "step_number": 2,
      "step_content": "å»ºç«‹åŒç†å¿ƒï¼šè®¤å¯å®¢æˆ·é¡¾è™‘",
      "is_correct": true,
      "is_necessary": true,
      "feedback": "å»ºç«‹åŒç†å¿ƒæ˜¯å…³é”®æ­¥éª¤ï¼Œæœ‰åŠ©äºé™ä½å®¢æˆ·é˜²å¾¡å¿ƒç†",
      "score": 0.90
    },
    {
      "step_number": 3,
      "step_content": "ä»·å€¼è½¬åŒ–ï¼šè¯´æ˜æƒç›Šä»·å€¼",
      "is_correct": true,
      "is_necessary": true,
      "feedback": "ä»·å€¼è½¬åŒ–æ˜¯æ ¸å¿ƒæŠ€å·§ï¼Œå°†ä»·æ ¼è½¬åŒ–ä¸ºä»·å€¼",
      "score": 0.92
    },
    {
      "step_number": 4,
      "step_content": "æä¾›è§£å†³æ–¹æ¡ˆï¼šæ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹",
      "is_correct": true,
      "is_necessary": true,
      "feedback": "æä¾›å…·ä½“è§£å†³æ–¹æ¡ˆï¼Œç»™å®¢æˆ·æ˜ç¡®çš„è¡ŒåŠ¨è·¯å¾„",
      "score": 0.88
    }
  ],
  "overall_process_score": 0.91,
  "process_strengths": ["é€»è¾‘æ¸…æ™°", "è€ƒè™‘å…¨é¢", "æ­¥éª¤å®Œæ•´"],
  "process_weaknesses": ["å¯ä»¥æ›´å¿«åˆ‡å…¥æ ¸å¿ƒ", "å¯ä»¥è¡¥å……æ•°æ®æ”¯æ’‘"],
  "process_suggestions": ["å»ºè®®åœ¨æ­¥éª¤2å’Œ3ä¹‹é—´å¢åŠ éœ€æ±‚ç¡®è®¤", "å¯ä»¥åœ¨æ­¥éª¤4åå¢åŠ ä¿ƒæˆç¯èŠ‚"]
}"""

        # Constitutional checking
        elif "æ£€æŸ¥ä»¥ä¸‹é”€å”®å›åº”æ˜¯å¦è¿åäº†åˆè§„è§„åˆ™" in prompt:
            if "å¿…é¡»ä»Šå¤©åŠç†" in prompt:
                return """{
  "is_compliant": false,
  "violations": [
    {
      "rule": "no_pressure",
      "violated": true,
      "evidence": "ä½¿ç”¨äº†'å¿…é¡»ä»Šå¤©åŠç†ï¼Œå¦åˆ™æ˜å¤©å°±æ¶¨ä»·'ç­‰é«˜å‹è¯æœ¯",
      "severity": "high"
    },
    {
      "rule": "no_false_promises",
      "violated": false,
      "evidence": "",
      "severity": "low"
    },
    {
      "rule": "transparency",
      "violated": false,
      "evidence": "",
      "severity": "low"
    }
  ],
  "overall_risk_level": "high",
  "recommendations": ["ç§»é™¤æ—¶é—´å‹åŠ›è¯æœ¯", "æ”¹ç”¨å’¨è¯¢å¼é”€å”®æ–¹æ³•", "æä¾›å®¢è§‚çš„äº§å“ä¿¡æ¯"]
}"""
            else:
                return """{
  "is_compliant": true,
  "violations": [
    {
      "rule": "no_false_promises",
      "violated": false,
      "evidence": "",
      "severity": "low"
    },
    {
      "rule": "no_pressure",
      "violated": false,
      "evidence": "",
      "severity": "low"
    },
    {
      "rule": "transparency",
      "violated": false,
      "evidence": "",
      "severity": "low"
    }
  ],
  "overall_risk_level": "low",
  "recommendations": ["ç»§ç»­ä¿æŒåˆè§„çš„é”€å”®æ–¹å¼"]
}"""

        return "{}"


# ==================== Test Functions ====================

async def test_graph_rag_enhanced():
    """Test Enhanced GraphRAG."""
    logger.info("=" * 60)
    logger.info("Testing Enhanced GraphRAG")
    logger.info("=" * 60)

    from app.infra.search.graph_rag_enhanced import EnhancedGraphRAGService

    # Initialize
    llm_client = MockLLMClient()
    graph_rag = EnhancedGraphRAGService(
        org_id="test_org",
        llm_client=llm_client,
        enable_multi_hop=True,
        max_reasoning_hops=3,
    )

    # Test 1: Ingest sales conversation
    logger.info("\n[Test 1] Ingesting sales conversation...")
    conversation = """
å®¢æˆ·ï¼šä½ ä»¬çš„ä¿¡ç”¨å¡å¹´è´¹å¤ªè´µäº†ï¼Œ1000å…ƒä¸€å¹´ã€‚
é”€å† ï¼šæˆ‘ç†è§£æ‚¨çš„é¡¾è™‘ã€‚å…¶å®æˆ‘ä»¬çš„ç™½é‡‘å¡è™½ç„¶å¹´è´¹1000å…ƒï¼Œ
     ä½†åªè¦æ‚¨å¹´æ¶ˆè´¹æ»¡10ä¸‡ï¼Œå¹´è´¹å°±å…¨å…ã€‚è€Œä¸”æ‚¨å¯ä»¥äº«å—
     æœºåœºè´µå®¾å…ã€ç§¯åˆ†è¿”ç°ç­‰ä»·å€¼è¶…è¿‡5000å…ƒçš„æƒç›Šã€‚
å®¢æˆ·ï¼šå“¦ï¼Œè¿™æ ·å•Šã€‚é‚£å…·ä½“æœ‰å“ªäº›æƒç›Šå‘¢ï¼Ÿ
é”€å† ï¼šä¸»è¦åŒ…æ‹¬ï¼šå…¨çƒæœºåœºè´µå®¾å…ã€æ¶ˆè´¹ç§¯åˆ†è¿”ç°ã€ç”Ÿæ—¥ç¤¼é‡ã€
     ä¸“å±å®¢æœç­‰ã€‚è¿™äº›æƒç›Šçš„å¸‚åœºä»·å€¼è¿œè¶…å¹´è´¹ã€‚
    """

    result = await graph_rag.ingest_sales_conversation(
        conversation_id="conv_001",
        conversation_text=conversation,
        metadata={"sales_champion": "å¼ ä¸‰", "success": True}
    )

    logger.info(f"Ingestion result: {result}")
    logger.info(f"  - Entities: {result['total_entities']}")
    logger.info(f"  - Relations: {result['total_relations']}")
    logger.info(f"  - Entity types: {result['entity_types']}")

    # Test 2: Answer complex query
    logger.info("\n[Test 2] Answering complex query...")
    query = "å®¢æˆ·è¯´å¹´è´¹å¤ªè´µï¼Œé”€å† é€šå¸¸æ€ä¹ˆåº”å¯¹ï¼Ÿ"

    answer_result = await graph_rag.answer_complex_query(
        query=query,
        use_multi_hop=True
    )

    logger.info(f"Query: {query}")
    logger.info(f"Answer: {answer_result['answer']}")
    logger.info(f"Confidence: {answer_result['confidence']:.2f}")
    logger.info(f"Reasoning paths: {len(answer_result['reasoning_paths'])}")

    for i, path in enumerate(answer_result['reasoning_paths'][:2], 1):
        logger.info(f"\n  Path {i}:")
        logger.info(f"    Entities: {' â†’ '.join(path['entities'])}")
        logger.info(f"    Reasoning: {path['reasoning']}")
        logger.info(f"    Score: {path['score']:.2f}")

    # Test 3: Get stats
    logger.info("\n[Test 3] Getting statistics...")
    stats = graph_rag.get_stats()
    logger.info(f"GraphRAG stats: {stats}")

    logger.info("\nâœ… Enhanced GraphRAG tests completed!")


async def test_rlaif_evaluator():
    """Test RLAIF Evaluator."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing RLAIF Evaluator")
    logger.info("=" * 60)

    from app.evaluation.rlaif_evaluator import RLAIFEvaluator

    # Initialize
    llm_client = MockLLMClient()
    evaluator = RLAIFEvaluator(llm_client)

    # Test 1: Comprehensive evaluation
    logger.info("\n[Test 1] Comprehensive evaluation...")
    customer_input = "ä½ ä»¬çš„ä¿¡ç”¨å¡å¹´è´¹å¤ªè´µäº†"
    sales_response = """æˆ‘ç†è§£æ‚¨çš„é¡¾è™‘ã€‚å…¶å®æˆ‘ä»¬çš„ç™½é‡‘å¡è™½ç„¶å¹´è´¹1000å…ƒï¼Œ
ä½†åªè¦æ‚¨å¹´æ¶ˆè´¹æ»¡10ä¸‡ï¼Œå¹´è´¹å°±å…¨å…ã€‚è€Œä¸”æ‚¨å¯ä»¥äº«å—æœºåœºè´µå®¾å…ã€
ç§¯åˆ†è¿”ç°ç­‰ä»·å€¼è¶…è¿‡5000å…ƒçš„æƒç›Šã€‚"""
    thought_process = """
1. è¯†åˆ«å¼‚è®®ç±»å‹ï¼šä»·æ ¼å¼‚è®®
2. å»ºç«‹åŒç†å¿ƒï¼šè®¤å¯å®¢æˆ·é¡¾è™‘
3. ä»·å€¼è½¬åŒ–ï¼šè¯´æ˜æƒç›Šä»·å€¼
4. æä¾›è§£å†³æ–¹æ¡ˆï¼šæ¶ˆè´¹è¾¾æ ‡å…å¹´è´¹
    """

    evaluation = await evaluator.evaluate_comprehensive(
        customer_input=customer_input,
        sales_response=sales_response,
        thought_process=thought_process
    )

    logger.info(f"Overall score: {evaluation.overall_score:.2f}")
    logger.info(f"\nDimension scores:")
    for score in evaluation.dimension_scores:
        logger.info(f"  {score.dimension.value}: {score.score:.2f}")
        logger.info(f"    Reasoning: {score.reasoning}")

    logger.info(f"\nStrengths: {evaluation.strengths}")
    logger.info(f"Weaknesses: {evaluation.weaknesses}")
    logger.info(f"Suggestions: {evaluation.suggestions}")
    logger.info(f"Compliance issues: {evaluation.compliance_issues}")
    logger.info(f"Process feedback steps: {len(evaluation.process_feedback)}")

    # Test 2: Pairwise comparison
    logger.info("\n[Test 2] Pairwise comparison...")
    response_a = "å¹´è´¹å¯ä»¥å…é™¤çš„ï¼Œæ‚¨æ¶ˆè´¹æ»¡10ä¸‡å°±è¡Œã€‚"
    response_b = """æˆ‘ç†è§£æ‚¨çš„é¡¾è™‘ã€‚å¹´è´¹ç¡®å®æ˜¯ä¸€ç¬”æ”¯å‡ºï¼Œä½†æˆ‘ä»¬çš„æƒç›Šä»·å€¼è¿œè¶…å¹´è´¹ã€‚
åªè¦æ‚¨å¹´æ¶ˆè´¹æ»¡10ä¸‡ï¼Œå¹´è´¹å°±å…¨å…ï¼Œè€Œä¸”æ‚¨å¯ä»¥äº«å—ä»·å€¼è¶…è¿‡5000å…ƒçš„æƒç›Šã€‚"""

    comparison = await evaluator.pairwise_comparator.compare(
        customer_input=customer_input,
        response_a=response_a,
        response_b=response_b
    )

    logger.info(f"Preferred: {comparison.preferred}")
    logger.info(f"Confidence: {comparison.confidence:.2f}")
    logger.info(f"Reasoning: {comparison.reasoning}")

    # Test 3: Rank responses
    logger.info("\n[Test 3] Ranking responses...")
    responses = [
        ("novice", "å¹´è´¹å¯ä»¥å…é™¤..."),
        ("champion", "æˆ‘ç†è§£æ‚¨çš„é¡¾è™‘..."),
        ("average", "è¿™ä¸ªä»·æ ¼å¾ˆåˆç†..."),
    ]

    ranked = await evaluator.rank_responses(
        customer_input=customer_input,
        responses=responses
    )

    logger.info("Ranking results:")
    for i, (response_id, score) in enumerate(ranked, 1):
        logger.info(f"  {i}. {response_id}: {score:.2f}")

    # Test 4: Constitutional checking
    logger.info("\n[Test 4] Constitutional checking...")

    # Test compliant response
    compliant_response = "æˆ‘ç†è§£æ‚¨çš„é¡¾è™‘ã€‚è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†ä»‹ç»ä¸€ä¸‹æˆ‘ä»¬çš„æƒç›Š..."
    compliant_result = await evaluator.constitutional_checker.check(compliant_response)
    logger.info(f"Compliant response check:")
    logger.info(f"  Is compliant: {compliant_result['is_compliant']}")
    logger.info(f"  Risk level: {compliant_result['overall_risk_level']}")

    # Test non-compliant response
    non_compliant_response = "æ‚¨å¿…é¡»ä»Šå¤©åŠç†ï¼Œå¦åˆ™æ˜å¤©å°±æ¶¨ä»·äº†ï¼"
    non_compliant_result = await evaluator.constitutional_checker.check(non_compliant_response)
    logger.info(f"\nNon-compliant response check:")
    logger.info(f"  Is compliant: {non_compliant_result['is_compliant']}")
    logger.info(f"  Risk level: {non_compliant_result['overall_risk_level']}")
    logger.info(f"  Violations:")
    for violation in non_compliant_result['violations']:
        if violation['violated']:
            logger.info(f"    - {violation['rule']}: {violation['evidence']}")
            logger.info(f"      Severity: {violation['severity']}")

    logger.info("\nâœ… RLAIF Evaluator tests completed!")


async def main():
    """Run all tests."""
    logger.info("Starting GraphRAG + RLAIF tests...\n")

    try:
        # Test GraphRAG
        await test_graph_rag_enhanced()

        # Test RLAIF
        await test_rlaif_evaluator()

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ All tests completed successfully!")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"Test failed: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    asyncio.run(main())
