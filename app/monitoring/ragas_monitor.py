"""
RAGAS æŒç»­è¯„ä¼°å’Œç›‘æ§ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. æŒç»­è¯„ä¼° RAG è´¨é‡
2. è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
3. æ€§èƒ½è¿½è¸ª
4. å‘Šè­¦ç³»ç»Ÿ
"""
from __future__ import annotations

import asyncio
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np

from app.evaluation.ragas_evaluator import (
    RAGASBatchEvaluator,
    RAGASEvaluationInput,
    RAGASEvaluator,
)

logger = logging.getLogger(__name__)


class RAGASMonitor:
    """
    RAGAS æŒç»­ç›‘æ§ç³»ç»Ÿ

    åŠŸèƒ½ï¼š
    1. å®šæœŸè¯„ä¼°
    2. æ€§èƒ½è¿½è¸ª
    3. å‘Šè­¦
    4. æŠ¥å‘Šç”Ÿæˆ
    """

    def __init__(
        self,
        evaluator: RAGASEvaluator,
        storage_path: str = "./monitoring/ragas",
        alert_threshold: float = 0.6,
    ):
        """
        åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ

        Args:
            evaluator: RAGAS è¯„ä¼°å™¨
            storage_path: å­˜å‚¨è·¯å¾„
            alert_threshold: å‘Šè­¦é˜ˆå€¼
        """
        self.evaluator = evaluator
        self.batch_evaluator = RAGASBatchEvaluator(evaluator)
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)
        self.alert_threshold = alert_threshold

        # å†å²æ•°æ®
        self.history: List[Dict[str, Any]] = []
        self._load_history()

    def _load_history(self):
        """åŠ è½½å†å²æ•°æ®"""
        history_file = self.storage_path / "history.json"

        if history_file.exists():
            try:
                with open(history_file, "r") as f:
                    self.history = json.load(f)
                logger.info(f"Loaded {len(self.history)} historical evaluations")
            except Exception as e:
                logger.error(f"Failed to load history: {e}")
                self.history = []

    def _save_history(self):
        """ä¿å­˜å†å²æ•°æ®"""
        history_file = self.storage_path / "history.json"

        try:
            with open(history_file, "w") as f:
                json.dump(self.history, f, indent=2)
        except Exception as e:
            logger.error(f"Failed to save history: {e}")

    async def evaluate_and_record(
        self, test_cases: List[RAGASEvaluationInput], metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°å¹¶è®°å½•ç»“æœ

        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹
            metadata: å…ƒæ•°æ®

        Returns:
            è¯„ä¼°ç»“æœ
        """
        logger.info(f"Evaluating {len(test_cases)} test cases")

        # è¯„ä¼°
        results = await self.batch_evaluator.evaluate_batch(test_cases)

        # æ·»åŠ æ—¶é—´æˆ³å’Œå…ƒæ•°æ®
        record = {
            "timestamp": datetime.now().isoformat(),
            "num_test_cases": len(test_cases),
            "metrics": results["metrics"],
            "metadata": metadata or {},
        }

        # è®°å½•
        self.history.append(record)
        self._save_history()

        # æ£€æŸ¥å‘Šè­¦
        await self._check_alerts(record)

        # ç”ŸæˆæŠ¥å‘Š
        await self._generate_report(record)

        return results

    async def _check_alerts(self, record: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦"""
        metrics = record["metrics"]

        alerts = []

        # æ£€æŸ¥å„é¡¹æŒ‡æ ‡
        for metric_name, metric_data in metrics.items():
            mean_value = metric_data["mean"]

            if mean_value < self.alert_threshold:
                alerts.append(
                    {
                        "metric": metric_name,
                        "value": mean_value,
                        "threshold": self.alert_threshold,
                        "severity": "high" if mean_value < 0.5 else "medium",
                    }
                )

        if alerts:
            logger.warning(f"âš ï¸  Quality alerts triggered: {len(alerts)} issues")

            for alert in alerts:
                logger.warning(
                    f"  - {alert['metric']}: {alert['value']:.3f} < {alert['threshold']:.3f}"
                )

            # ä¿å­˜å‘Šè­¦
            await self._save_alert(record, alerts)

    async def _save_alert(self, record: Dict[str, Any], alerts: List[Dict]):
        """ä¿å­˜å‘Šè­¦"""
        alert_file = self.storage_path / f"alert_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(alert_file, "w") as f:
                json.dump(
                    {
                        "timestamp": record["timestamp"],
                        "alerts": alerts,
                        "metrics": record["metrics"],
                    },
                    f,
                    indent=2,
                )
        except Exception as e:
            logger.error(f"Failed to save alert: {e}")

    async def _generate_report(self, record: Dict[str, Any]):
        """ç”ŸæˆæŠ¥å‘Š"""
        report_file = self.storage_path / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

        try:
            report = self._format_report(record)

            with open(report_file, "w") as f:
                f.write(report)

            logger.info(f"Report generated: {report_file}")

        except Exception as e:
            logger.error(f"Failed to generate report: {e}")

    def _format_report(self, record: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æŠ¥å‘Š"""
        metrics = record["metrics"]

        report = f"""# RAGAS è¯„ä¼°æŠ¥å‘Š

**æ—¶é—´**: {record['timestamp']}
**æµ‹è¯•ç”¨ä¾‹æ•°**: {record['num_test_cases']}

## æŒ‡æ ‡æ¦‚è§ˆ

| æŒ‡æ ‡ | å¹³å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | çŠ¶æ€ |
|------|--------|--------|--------|--------|------|
"""

        for metric_name, metric_data in metrics.items():
            mean = metric_data["mean"]
            std = metric_data["std"]
            min_val = metric_data["min"]
            max_val = metric_data["max"]

            status = "âœ…" if mean >= self.alert_threshold else "âš ï¸"

            report += f"| {metric_name} | {mean:.3f} | {std:.3f} | {min_val:.3f} | {max_val:.3f} | {status} |\n"

        # æ·»åŠ è¶‹åŠ¿åˆ†æ
        if len(self.history) > 1:
            report += "\n## è¶‹åŠ¿åˆ†æ\n\n"
            report += self._format_trend_analysis()

        # æ·»åŠ å»ºè®®
        report += "\n## æ”¹è¿›å»ºè®®\n\n"
        report += self._format_recommendations(metrics)

        return report

    def _format_trend_analysis(self) -> str:
        """æ ¼å¼åŒ–è¶‹åŠ¿åˆ†æ"""
        if len(self.history) < 2:
            return "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æã€‚\n"

        # è·å–æœ€è¿‘ 10 æ¬¡è¯„ä¼°
        recent = self.history[-10:]

        # è®¡ç®—è¶‹åŠ¿
        trends = {}

        for metric_name in ["context_precision", "context_recall", "faithfulness", "answer_relevance"]:
            values = [r["metrics"][metric_name]["mean"] for r in recent]

            if len(values) >= 2:
                # ç®€å•çº¿æ€§è¶‹åŠ¿
                trend = values[-1] - values[0]
                trends[metric_name] = trend

        # æ ¼å¼åŒ–
        text = ""

        for metric_name, trend in trends.items():
            if trend > 0.05:
                text += f"- **{metric_name}**: ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿ (+{trend:.3f})\n"
            elif trend < -0.05:
                text += f"- **{metric_name}**: ğŸ“‰ ä¸‹é™è¶‹åŠ¿ ({trend:.3f})\n"
            else:
                text += f"- **{metric_name}**: â¡ï¸ ç¨³å®š\n"

        return text

    def _format_recommendations(self, metrics: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ”¹è¿›å»ºè®®"""
        recommendations = []

        # Context Precision
        if metrics["context_precision"]["mean"] < 0.7:
            recommendations.append(
                "- **æå‡æ£€ç´¢ç²¾åº¦**: è€ƒè™‘ä½¿ç”¨ HyDE æˆ–æ”¹è¿›æŸ¥è¯¢é‡å†™"
            )

        # Context Recall
        if metrics["context_recall"]["mean"] < 0.7:
            recommendations.append(
                "- **æå‡æ£€ç´¢å¬å›**: å¢åŠ  top_k æˆ–ä½¿ç”¨æ··åˆæ£€ç´¢"
            )

        # Faithfulness
        if metrics["faithfulness"]["mean"] < 0.8:
            recommendations.append(
                "- **å‡å°‘å¹»è§‰**: ä½¿ç”¨ Self-RAG æˆ–åŠ å¼ºæç¤ºè¯çº¦æŸ"
            )

        # Answer Relevance
        if metrics["answer_relevance"]["mean"] < 0.7:
            recommendations.append(
                "- **æå‡ç­”æ¡ˆç›¸å…³æ€§**: ä¼˜åŒ–ç”Ÿæˆæç¤ºè¯æˆ–ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹"
            )

        if not recommendations:
            recommendations.append("- âœ… æ‰€æœ‰æŒ‡æ ‡è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼")

        return "\n".join(recommendations)

    def get_dashboard_data(self) -> Dict[str, Any]:
        """è·å–ä»ªè¡¨æ¿æ•°æ®"""
        if not self.history:
            return {"error": "No data available"}

        # æœ€è¿‘ 30 å¤©æ•°æ®
        cutoff = datetime.now() - timedelta(days=30)
        recent = [
            r
            for r in self.history
            if datetime.fromisoformat(r["timestamp"]) > cutoff
        ]

        if not recent:
            recent = self.history[-10:]  # è‡³å°‘æ˜¾ç¤ºæœ€è¿‘ 10 æ¬¡

        # æå–æ—¶é—´åºåˆ—æ•°æ®
        timestamps = [r["timestamp"] for r in recent]

        metrics_over_time = {}

        for metric_name in ["context_precision", "context_recall", "faithfulness", "answer_relevance", "overall_score"]:
            metrics_over_time[metric_name] = [
                r["metrics"][metric_name]["mean"] for r in recent
            ]

        # å½“å‰çŠ¶æ€
        latest = recent[-1]

        return {
            "timestamps": timestamps,
            "metrics_over_time": metrics_over_time,
            "latest_metrics": latest["metrics"],
            "total_evaluations": len(self.history),
            "recent_evaluations": len(recent),
        }


class RAGASScheduler:
    """
    RAGAS å®šæ—¶è¯„ä¼°è°ƒåº¦å™¨

    åŠŸèƒ½ï¼š
    1. å®šæ—¶è¯„ä¼°
    2. è‡ªåŠ¨é‡‡æ ·
    3. æŒç»­ç›‘æ§
    """

    def __init__(
        self,
        monitor: RAGASMonitor,
        interval_hours: int = 24,
    ):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨

        Args:
            monitor: RAGAS ç›‘æ§å™¨
            interval_hours: è¯„ä¼°é—´éš”ï¼ˆå°æ—¶ï¼‰
        """
        self.monitor = monitor
        self.interval_hours = interval_hours
        self.running = False

    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        self.running = True

        logger.info(f"RAGAS scheduler started (interval: {self.interval_hours}h)")

        while self.running:
            try:
                # æ‰§è¡Œè¯„ä¼°
                await self._run_evaluation()

                # ç­‰å¾…ä¸‹æ¬¡è¯„ä¼°
                await asyncio.sleep(self.interval_hours * 3600)

            except Exception as e:
                logger.error(f"Evaluation failed: {e}")
                await asyncio.sleep(3600)  # é”™è¯¯åç­‰å¾… 1 å°æ—¶

    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.running = False
        logger.info("RAGAS scheduler stopped")

    async def _run_evaluation(self):
        """è¿è¡Œè¯„ä¼°"""
        logger.info("Running scheduled RAGAS evaluation")

        # è¿™é‡Œéœ€è¦ä»ç”Ÿäº§ç¯å¢ƒé‡‡æ ·æµ‹è¯•ç”¨ä¾‹
        # å®é™…å®ç°ä¸­ï¼Œåº”è¯¥ä»æ—¥å¿—æˆ–æ•°æ®åº“ä¸­é‡‡æ ·çœŸå®çš„æŸ¥è¯¢å’Œç­”æ¡ˆ

        # ç¤ºä¾‹ï¼šä»æ—¥å¿—é‡‡æ ·
        test_cases = await self._sample_test_cases()

        if test_cases:
            await self.monitor.evaluate_and_record(
                test_cases,
                metadata={"source": "scheduled", "interval_hours": self.interval_hours},
            )

    async def _sample_test_cases(self) -> List[RAGASEvaluationInput]:
        """ä»ç”Ÿäº§ç¯å¢ƒé‡‡æ ·æµ‹è¯•ç”¨ä¾‹"""
        # TODO: å®ç°ä»æ—¥å¿—/æ•°æ®åº“é‡‡æ ·
        # è¿™é‡Œè¿”å›ç©ºåˆ—è¡¨ä½œä¸ºç¤ºä¾‹
        return []
