# ä»»åŠ¡ç¼–æ’ç³»ç»Ÿæ”¹è¿›å®ç°æŠ¥å‘Š

## æ¦‚è¿°

æœ¬æ–‡æ¡£æ€»ç»“äº†å¯¹SalesBoostä»»åŠ¡ç¼–æ’ç³»ç»Ÿçš„å…¨é¢æ”¹è¿›å®ç°ï¼Œæ¶µç›–å¯è§‚æµ‹æ€§ã€ç”¨æˆ·åé¦ˆã€é…ç½®ç®¡ç†ã€æµ‹è¯•ã€å¼‚æ­¥å¤„ç†ã€ç®—æ³•ä¼˜åŒ–ç­‰å¤šä¸ªæ–¹é¢ã€‚

## å·²å®ç°åŠŸèƒ½æ¸…å•

### âœ… 1. Prometheusç›‘æ§é›†æˆ

**æ–‡ä»¶**: `app/observability/coordinator_metrics.py`

**åŠŸèƒ½**:
- å®Œæ•´çš„Prometheus metricså®šä¹‰
- èŠ‚ç‚¹æ‰§è¡Œç›‘æ§ï¼ˆæ‰§è¡Œæ¬¡æ•°ã€è€—æ—¶ï¼‰
- è·¯ç”±å†³ç­–ç›‘æ§ï¼ˆæ¥æºã€ç›®æ ‡ã€ç½®ä¿¡åº¦ï¼‰
- Reasoning Engineç›‘æ§
- Banditç®—æ³•ç›‘æ§ï¼ˆå†³ç­–ã€å¥–åŠ±ã€armå¾—åˆ†ï¼‰
- Coachå»ºè®®ç›‘æ§ï¼ˆæ¥æºã€é™çº§æ¬¡æ•°ï¼‰
- åˆè§„æ£€æŸ¥ç›‘æ§ï¼ˆé£é™©ç­‰çº§ã€åˆ†æ•°ï¼‰
- Turnæ‰§è¡Œç›‘æ§ï¼ˆTTFTã€æ€»è€—æ—¶ï¼‰
- ç”¨æˆ·åé¦ˆç›‘æ§ï¼ˆè¯„åˆ†åˆ†å¸ƒã€æ»¡æ„åº¦ï¼‰

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from app.observability.coordinator_metrics import record_node_execution

record_node_execution(
    node_type="intent",
    duration_seconds=0.15,
    status="ok",
    engine="dynamic_workflow"
)
```

**Grafana Dashboardé…ç½®**:
```yaml
# ç¤ºä¾‹æŸ¥è¯¢
- èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸç‡: rate(coordinator_node_execution_total{status="ok"}[5m])
- å¹³å‡TTFT: histogram_quantile(0.95, coordinator_turn_ttft_seconds_bucket)
- Bandit armæ€§èƒ½: coordinator_bandit_arm_score
```

---

### âœ… 2. ç”¨æˆ·åé¦ˆæ”¶é›†API

**æ–‡ä»¶**: `api/endpoints/user_feedback.py`

**åŠŸèƒ½**:
- RESTful APIæ¥å£æ”¶é›†ç”¨æˆ·è¯„åˆ†ï¼ˆ1-5æ˜Ÿï¼‰
- è‡ªåŠ¨è½¬æ¢è¯„åˆ†ä¸ºBandit rewardä¿¡å·ï¼ˆ-1åˆ°1ï¼‰
- RedisæŒä¹…åŒ–å­˜å‚¨
- æ‰¹é‡åé¦ˆæäº¤
- ä¼šè¯åé¦ˆç»Ÿè®¡æŸ¥è¯¢

**APIç«¯ç‚¹**:

#### POST `/api/v1/feedback/submit`
æäº¤å•æ¡åé¦ˆ
```json
{
  "session_id": "abc123",
  "turn_number": 3,
  "rating": 5,
  "intent": "price_inquiry",
  "decision_id": "bandit_decision_xyz",
  "signals": {
    "response_quality": 0.9,
    "latency_satisfaction": 0.8
  }
}
```

#### GET `/api/v1/feedback/stats/{session_id}`
è·å–ä¼šè¯åé¦ˆç»Ÿè®¡

#### POST `/api/v1/feedback/batch-submit`
æ‰¹é‡æäº¤åé¦ˆ

**é›†æˆæ–¹å¼**:
```python
# åœ¨WebSocket handlerä¸­
async def on_user_rating(session_id, turn_number, rating):
    await submit_feedback(UserFeedbackRequest(
        session_id=session_id,
        turn_number=turn_number,
        rating=rating,
        decision_id=coordinator.last_bandit_decision_id
    ))
```

---

### âœ… 3. ç»Ÿä¸€é…ç½®ç®¡ç†ç³»ç»Ÿ

**æ–‡ä»¶**: `app/config/unified_config.py`

**åŠŸèƒ½**:
- å¤šæºé…ç½®åŠ è½½ï¼ˆRedis > File > Env > Defaultï¼‰
- çƒ­æ›´æ–°æ”¯æŒï¼ˆè‡ªåŠ¨reloadï¼‰
- é…ç½®å˜æ›´é€šçŸ¥æœºåˆ¶
- é…ç½®æŒä¹…åŒ–ï¼ˆRedis + Fileï¼‰
- é…ç½®å…ƒæ•°æ®è¿½è¸ª

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from app.config.unified_config import get_config_manager

# åˆå§‹åŒ–
manager = await get_config_manager()

# è·å–é…ç½®
config = manager.get_workflow_config()

# æ³¨å†Œå˜æ›´ç›‘å¬
manager.on_config_change(lambda cfg: print(f"Config changed: {cfg.name}"))

# æ›´æ–°é…ç½®
new_config = WorkflowConfig(name="new_workflow", ...)
await manager.update_config(new_config, persist=True)
```

**é…ç½®æ–‡ä»¶æ ¼å¼** (`config/workflow_config.json`):
```json
{
  "name": "production_workflow",
  "version": "2.0",
  "enabled_nodes": ["intent", "knowledge", "npc", "coach", "compliance"],
  "routing_rules": {
    "intent": ["knowledge"],
    "knowledge": ["npc"],
    "npc": ["coach"],
    "coach": ["compliance"]
  },
  "enable_reasoning": true,
  "enable_routing_policy": true,
  "enable_bandit": true,
  "bandit_exploration_rate": 0.1
}
```

---

### âœ… 4. ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

**æ–‡ä»¶**: `tests/integration/test_coordinator_e2e.py`

**æµ‹è¯•è¦†ç›–**:
- å•è½®å¯¹è¯æµ‹è¯•
- å¤šè½®å¯¹è¯æµç¨‹æµ‹è¯•
- çŸ¥è¯†æ£€ç´¢é›†æˆæµ‹è¯•
- Coachå»ºè®®ç”Ÿæˆæµ‹è¯•ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰
- é”™è¯¯å¤„ç†å’Œé™çº§æµ‹è¯•
- Banditå†³ç­–è®°å½•æµ‹è¯•
- æ€§èƒ½æŒ‡æ ‡æµ‹è¯•ï¼ˆTTFTã€trace logï¼‰

**è¿è¡Œæµ‹è¯•**:
```bash
pytest tests/integration/test_coordinator_e2e.py -v -s
```

**æµ‹è¯•ç¤ºä¾‹**:
```python
@pytest.mark.asyncio
async def test_multi_turn_conversation(minimal_coordinator):
    # Turn 1: Greeting
    result1 = await minimal_coordinator.execute_turn(1, "ä½ å¥½", False)
    assert result1.intent == "greeting"

    # Turn 2: Product inquiry
    result2 = await minimal_coordinator.execute_turn(2, "ä½ ä»¬çš„äº§å“æœ‰ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ", False)
    assert result2.intent == "product_inquiry"

    # Turn 3: Price inquiry
    result3 = await minimal_coordinator.execute_turn(3, "å¤šå°‘é’±ï¼Ÿ", False)
    assert result3.intent == "price_inquiry"
```

---

### âœ… 5. Celeryå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—

**æ–‡ä»¶**: `app/tasks/coach_tasks.py`

**åŠŸèƒ½**:
- å¼‚æ­¥Coachå»ºè®®ç”Ÿæˆ
- WebSocketè‡ªåŠ¨æ¨é€
- Redisç»“æœå­˜å‚¨
- æ‰¹é‡ä»»åŠ¡å¤„ç†
- ä»»åŠ¡é‡è¯•æœºåˆ¶

**Celeryé…ç½®**:
```python
celery_app = Celery(
    'salesboost_tasks',
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from app.tasks.coach_tasks import trigger_async_coach_advice

# è§¦å‘å¼‚æ­¥ä»»åŠ¡
task_id = trigger_async_coach_advice(
    session_id="abc123",
    turn_number=1,
    user_message="ä½ å¥½",
    npc_response="æ‚¨å¥½ï¼",
    history=[],
    intent="greeting"
)

# è·å–ç»“æœï¼ˆå¯é€‰ï¼‰
result = get_coach_advice_result(task_id, timeout=30)
```

**WebSocketæ¨é€**:
```javascript
// å‰ç«¯æ¥æ”¶
websocket.on('coach_advice', (data) => {
  console.log('Coach advice:', data.advice);
  displayCoachAdvice(data);
});
```

**å¯åŠ¨Celery Worker**:
```bash
celery -A app.tasks.coach_tasks worker --loglevel=info
```

---

### âœ… 6. DAGéªŒè¯

**æ–‡ä»¶**: `app/engine/coordinator/dynamic_workflow.py` (å·²ä¿®æ”¹)

**åŠŸèƒ½**:
- è‡ªåŠ¨æ£€æµ‹è·¯ç”±é…ç½®ä¸­çš„å¾ªç¯ä¾èµ–
- éªŒè¯æ‰€æœ‰å¼•ç”¨çš„èŠ‚ç‚¹éƒ½å·²å¯ç”¨
- æ£€æŸ¥æ˜¯å¦å­˜åœ¨åˆ°ENDçš„è·¯å¾„
- ä½¿ç”¨Pydantic `@model_validator`è‡ªåŠ¨éªŒè¯

**éªŒè¯é€»è¾‘**:
```python
@model_validator(mode='after')
def validate_dag(self):
    # 1. æ£€æŸ¥æ‰€æœ‰å¼•ç”¨èŠ‚ç‚¹æ˜¯å¦å¯ç”¨
    # 2. ä½¿ç”¨DFSæ£€æµ‹å¾ªç¯
    # 3. ä½¿ç”¨BFSæ£€æŸ¥æ˜¯å¦å¯è¾¾END
    return self
```

**é”™è¯¯ç¤ºä¾‹**:
```python
# è¿™ä¼šæŠ›å‡ºValidationError
config = WorkflowConfig(
    enabled_nodes={NodeType.INTENT, NodeType.NPC},
    routing_rules={
        "intent": ["knowledge"],  # knowledgeæœªå¯ç”¨
        "knowledge": ["npc"]
    }
)
# ValueError: Routing references disabled nodes: {'knowledge'}
```

---

### âœ… 7. LinUCB Banditç®—æ³•

**æ–‡ä»¶**: `app/engine/coordinator/bandit_linucb.py`

**åŠŸèƒ½**:
- ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„LinUCBç®—æ³•
- ç‰¹å¾æå–ï¼ˆintent confidenceã€FSM stageã€need_toolsç­‰ï¼‰
- UCBç½®ä¿¡åº¦è®¡ç®—
- åœ¨çº¿å­¦ä¹ æ›´æ–°
- Hybrid LinUCBå˜ä½“ï¼ˆæ”¯æŒå…±äº«ç‰¹å¾ï¼‰

**ç®—æ³•åŸç†**:
```
UCB(arm) = Î¸^T * x + Î± * sqrt(x^T * A^-1 * x)
         = æœŸæœ›å¥–åŠ± + æ¢ç´¢å¥–åŠ±
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from app.engine.coordinator.bandit_linucb import LinUCBBandit

bandit = LinUCBBandit(
    arms=["npc", "tools", "knowledge"],
    context_dim=10,
    alpha=0.5
)

# å†³ç­–
context = {
    "intent": "price_inquiry",
    "confidence": 0.9,
    "fsm_stage": "negotiation",
    "need_tools": True
}
decision = bandit.choose(context)

# åé¦ˆ
bandit.record_feedback(
    decision_id=decision["decision_id"],
    reward=0.8
)

# ç»Ÿè®¡
stats = bandit.get_stats()
```

**ç‰¹å¾å·¥ç¨‹**:
- Intent confidence (1ç»´)
- FSM stage one-hot (5ç»´)
- Need tools binary (1ç»´)
- Risk flags count (1ç»´)
- Recent tool calls binary (1ç»´)
- Intent type (1ç»´)

---

### âœ… 8. Reasoning Engine Memory Buffer

**æ–‡ä»¶**: `app/engine/coordinator/reasoning_memory.py`

**åŠŸèƒ½**:
- å­˜å‚¨å†å²æ¨ç†ç»“æœ
- ä¼šè¯çº§åˆ«éš”ç¦»
- RedisæŒä¹…åŒ–
- ä¸Šä¸‹æ–‡æ‘˜è¦ç”Ÿæˆ
- ç›¸ä¼¼æƒ…å†µæ£€ç´¢

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from app.engine.coordinator.reasoning_memory import get_reasoning_memory

memory = get_reasoning_memory()

# å­˜å‚¨æ¨ç†ç»“æœ
memory.add(
    session_id="abc123",
    turn_number=1,
    reasoning={
        "analysis": ["User is greeting"],
        "core_concern": "establish rapport",
        "strategy": "friendly response"
    },
    intent="greeting",
    confidence=0.95
)

# è·å–æœ€è¿‘æ¨ç†
recent = memory.get_recent(session_id="abc123", n=3)

# è·å–ä¸Šä¸‹æ–‡æ‘˜è¦
context = memory.get_context_summary(session_id="abc123")
# è¾“å‡º: "Previous reasoning history:\n1. Turn 1 (greeting): Concern='establish rapport', Strategy='friendly response'"

# æŸ¥æ‰¾ç›¸ä¼¼æƒ…å†µ
similar = memory.get_similar_situations(
    session_id="abc123",
    current_intent="price_inquiry",
    n=2
)
```

**é›†æˆåˆ°Reasoning Engine**:
```python
# åœ¨reasoning_engine.pyä¸­
async def analyze(self, state: CoordinatorState) -> Tuple[Dict[str, Any], str]:
    # è·å–å†å²æ¨ç†ä¸Šä¸‹æ–‡
    memory = get_reasoning_memory()
    context_summary = memory.get_context_summary(
        session_id=state.get("session_id"),
        max_entries=3
    )

    # å°†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°prompt
    prompt = REASONING_USER_TEMPLATE.format(
        user_message=state.get("user_message"),
        previous_reasoning=context_summary,  # æ–°å¢
        ...
    )

    # æ‰§è¡Œæ¨ç†
    reasoning, source = await self._gateway.call(...)

    # å­˜å‚¨ç»“æœ
    memory.add(
        session_id=state.get("session_id"),
        turn_number=state.get("turn_number"),
        reasoning=reasoning,
        intent=state.get("intent"),
        confidence=state.get("confidence")
    )

    return reasoning, source
```

---

## å¾…å®ç°åŠŸèƒ½ï¼ˆé«˜çº§ç‰¹æ€§ï¼‰

### ğŸ”„ 9. æ€§èƒ½ç›‘æ§è£…é¥°å™¨ + OpenTelemetry

**å»ºè®®å®ç°**:
```python
# app/observability/tracing.py
from opentelemetry import trace
from functools import wraps

tracer = trace.get_tracer(__name__)

def trace_node_execution(node_name: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            with tracer.start_as_current_span(f"node.{node_name}") as span:
                span.set_attribute("node.name", node_name)
                result = await func(*args, **kwargs)
                span.set_attribute("node.status", "ok")
                return result
        return wrapper
    return decorator

# ä½¿ç”¨
@trace_node_execution("intent")
async def _intent_node(self, state: CoordinatorState):
    ...
```

---

### ğŸ”„ 10. è·¯ç”±ç­–ç•¥è½»é‡çº§åˆ†ç±»å™¨

**å»ºè®®å®ç°**:
```python
# app/engine/coordinator/routing_classifier.py
import xgboost as xgb
import numpy as np

class RoutingClassifier:
    """
    XGBoost-based routing classifier

    Trained on historical routing decisions to predict optimal routes
    Falls back to LLM when confidence is low
    """

    def __init__(self):
        self.model = xgb.XGBClassifier()
        self.is_trained = False

    def train(self, X, y):
        """Train on historical data"""
        self.model.fit(X, y)
        self.is_trained = True

    def predict(self, context):
        """Predict routing decision"""
        if not self.is_trained:
            return None, 0.0

        features = self._extract_features(context)
        proba = self.model.predict_proba([features])[0]
        predicted_class = np.argmax(proba)
        confidence = proba[predicted_class]

        return self.model.classes_[predicted_class], confidence
```

**æ•°æ®æ”¶é›†**:
```python
# åœ¨æ¯æ¬¡è·¯ç”±å†³ç­–å
routing_data = {
    "features": extract_features(state),
    "decision": routing_decision["target_node"],
    "reward": user_feedback_rating
}
store_routing_data(routing_data)
```

---

### ğŸ”„ 11. å¤šç›®æ ‡Paretoä¼˜åŒ–

**å»ºè®®å®ç°**:
```python
# app/engine/coordinator/pareto_optimizer.py
from typing import List, Dict
import numpy as np

class ParetoOptimizer:
    """
    Multi-objective optimization using Pareto dominance

    Objectives:
    - Maximize: conversion rate, user satisfaction
    - Minimize: cost, latency
    """

    def __init__(self, objectives: List[str]):
        self.objectives = objectives

    def is_dominated(self, solution_a, solution_b):
        """Check if solution_a is dominated by solution_b"""
        better_in_any = False
        worse_in_any = False

        for obj in self.objectives:
            if solution_b[obj] > solution_a[obj]:
                better_in_any = True
            elif solution_b[obj] < solution_a[obj]:
                worse_in_any = True

        return better_in_any and not worse_in_any

    def get_pareto_front(self, solutions: List[Dict]):
        """Get Pareto-optimal solutions"""
        pareto_front = []

        for solution in solutions:
            dominated = False
            for other in solutions:
                if self.is_dominated(solution, other):
                    dominated = True
                    break

            if not dominated:
                pareto_front.append(solution)

        return pareto_front
```

---

### ğŸ”„ 12. åŠ¨æ€Fallbackç”Ÿæˆï¼ˆFew-shot Learningï¼‰

**å»ºè®®å®ç°**:
```python
# app/engine/coordinator/dynamic_fallback.py
from typing import List, Dict

class DynamicFallbackGenerator:
    """
    Generate fallback advice using few-shot learning

    Retrieves successful examples from history and uses them as few-shot prompts
    """

    def __init__(self, model_gateway, redis_client):
        self.gateway = model_gateway
        self.redis = redis_client

    async def generate_fallback(
        self,
        intent: str,
        context: Dict,
        n_examples: int = 3
    ) -> str:
        """Generate fallback advice using few-shot learning"""

        # 1. Retrieve successful examples
        examples = await self._get_successful_examples(intent, n_examples)

        # 2. Build few-shot prompt
        prompt = self._build_few_shot_prompt(intent, context, examples)

        # 3. Generate advice
        advice = await self.gateway.call(prompt)

        return advice

    async def _get_successful_examples(self, intent: str, n: int) -> List[Dict]:
        """Retrieve successful coach advice examples from history"""
        # Query Redis for high-rated advice with same intent
        pattern = f"coach_advice:*:*:{intent}:rating:5"
        examples = []

        # Scan and retrieve
        cursor = 0
        while len(examples) < n:
            cursor, keys = await self.redis.scan(cursor, match=pattern, count=100)
            for key in keys:
                data = await self.redis.get(key)
                examples.append(json.loads(data))

            if cursor == 0:
                break

        return examples[:n]

    def _build_few_shot_prompt(self, intent, context, examples):
        """Build few-shot prompt with examples"""
        prompt_parts = [
            "Generate sales coach advice based on these successful examples:\n"
        ]

        for i, example in enumerate(examples, 1):
            prompt_parts.append(
                f"Example {i}:\n"
                f"Context: {example['context']}\n"
                f"Advice: {example['advice']}\n"
            )

        prompt_parts.append(
            f"\nNow generate advice for:\n"
            f"Intent: {intent}\n"
            f"Context: {context}\n"
            f"Advice:"
        )

        return "\n".join(prompt_parts)
```

---

## éƒ¨ç½²æŒ‡å—

### 1. å®‰è£…ä¾èµ–

```bash
pip install prometheus-client celery redis opentelemetry-api opentelemetry-sdk numpy
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# .env
REDIS_URL=redis://localhost:6379/0
COORDINATOR_ENGINE=dynamic_workflow
ALLOW_LEGACY_COORDINATOR=false
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨Celery worker
celery -A app.tasks.coach_tasks worker --loglevel=info

# å¯åŠ¨FastAPIåº”ç”¨
uvicorn main:app --host 0.0.0.0 --port 8000

# å¯åŠ¨Prometheus (å¯é€‰)
prometheus --config.file=config/prometheus.yml
```

### 4. é…ç½®Grafana Dashboard

å¯¼å…¥é¢„å®šä¹‰çš„dashboardé…ç½®ï¼š
```bash
curl -X POST http://localhost:3000/api/dashboards/db \
  -H "Content-Type: application/json" \
  -d @config/grafana/coordinator_dashboard.json
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. Redisè¿æ¥æ± 
```python
from redis import ConnectionPool

pool = ConnectionPool(
    host='localhost',
    port=6379,
    max_connections=50
)
redis_client = redis.Redis(connection_pool=pool)
```

### 2. Celeryå¹¶å‘é…ç½®
```bash
celery -A app.tasks.coach_tasks worker \
  --concurrency=4 \
  --pool=prefork \
  --max-tasks-per-child=1000
```

### 3. PrometheusæŒ‡æ ‡é‡‡æ ·
```python
# ä½¿ç”¨histogram bucketsä¼˜åŒ–
buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
```

---

## ç›‘æ§å‘Šè­¦è§„åˆ™

### Prometheus Alerting Rules

```yaml
# config/prometheus/alerts.yml
groups:
  - name: coordinator_alerts
    rules:
      - alert: HighTTFT
        expr: histogram_quantile(0.95, coordinator_turn_ttft_seconds_bucket) > 3
        for: 5m
        annotations:
          summary: "TTFT is too high (>3s)"

      - alert: LowUserSatisfaction
        expr: avg(coordinator_user_satisfaction_score) < 3
        for: 10m
        annotations:
          summary: "User satisfaction is low (<3 stars)"

      - alert: HighComplianceRisk
        expr: rate(coordinator_compliance_check_total{risk_level="BLOCK"}[5m]) > 0.1
        for: 5m
        annotations:
          summary: "High compliance risk rate"
```

---

## æ€»ç»“

æœ¬æ¬¡æ”¹è¿›å®ç°äº†ä»»åŠ¡ç¼–æ’ç³»ç»Ÿçš„8ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼š

1. âœ… **Prometheusç›‘æ§** - å®Œæ•´çš„metricsä½“ç³»
2. âœ… **ç”¨æˆ·åé¦ˆAPI** - é—­ç¯åé¦ˆæœºåˆ¶
3. âœ… **ç»Ÿä¸€é…ç½®ç®¡ç†** - çƒ­æ›´æ–°æ”¯æŒ
4. âœ… **é›†æˆæµ‹è¯•** - ç«¯åˆ°ç«¯æµ‹è¯•è¦†ç›–
5. âœ… **Celeryå¼‚æ­¥é˜Ÿåˆ—** - è‡ªåŠ¨WebSocketæ¨é€
6. âœ… **DAGéªŒè¯** - é…ç½®å®‰å…¨ä¿éšœ
7. âœ… **LinUCBç®—æ³•** - ä¸Šä¸‹æ–‡æ„ŸçŸ¥è·¯ç”±
8. âœ… **Memory Buffer** - æ¨ç†å†å²è®°å¿†

è¿™äº›æ”¹è¿›æ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„ï¼š
- **å¯è§‚æµ‹æ€§**: å…¨é¢çš„metricså’Œtracing
- **å¯é æ€§**: é…ç½®éªŒè¯ã€é”™è¯¯å¤„ç†ã€é™çº§ç­–ç•¥
- **æ€§èƒ½**: å¼‚æ­¥å¤„ç†ã€TTFTä¼˜åŒ–
- **æ™ºèƒ½æ€§**: LinUCBç®—æ³•ã€æ¨ç†è®°å¿†
- **å¯ç»´æŠ¤æ€§**: ç»Ÿä¸€é…ç½®ã€å®Œæ•´æµ‹è¯•

ç³»ç»Ÿå·²è¾¾åˆ°**ç”Ÿäº§çº§åˆ«**ï¼Œå»ºè®®ä¼˜å…ˆéƒ¨ç½²æ ¸å¿ƒåŠŸèƒ½ï¼Œç„¶åé€æ­¥æ·»åŠ é«˜çº§ç‰¹æ€§ï¼ˆè·¯ç”±åˆ†ç±»å™¨ã€Paretoä¼˜åŒ–ã€åŠ¨æ€Fallbackï¼‰ã€‚
