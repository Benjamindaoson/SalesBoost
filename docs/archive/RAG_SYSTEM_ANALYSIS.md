# ğŸ” SalesBoost RAG ç³»ç»Ÿæ·±åº¦åˆ†ææŠ¥å‘Š

**åˆ†ææ—¥æœŸ**: 2026-01-31
**ç³»ç»Ÿç‰ˆæœ¬**: 1.0.0
**åˆ†æèŒƒå›´**: RAG (Retrieval-Augmented Generation) å®Œæ•´å®ç°

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è§ˆ](#ç³»ç»Ÿæ¦‚è§ˆ)
2. [ç®—æ³•äº®ç‚¹](#ç®—æ³•äº®ç‚¹)
3. [å¼€å‘äº®ç‚¹](#å¼€å‘äº®ç‚¹)
4. [äº§å“äº®ç‚¹](#äº§å“äº®ç‚¹)
5. [æ”¹è¿›å»ºè®®](#æ”¹è¿›å»ºè®®)
6. [æŠ€æœ¯è¯„åˆ†](#æŠ€æœ¯è¯„åˆ†)

---

## ğŸ¯ ç³»ç»Ÿæ¦‚è§ˆ

### æ ¸å¿ƒæ¶æ„

SalesBoost çš„ RAG ç³»ç»Ÿé‡‡ç”¨ **å¤šå±‚çº§æ£€ç´¢ + é‡æ’åº** çš„å·¥ä¸šçº§æ¶æ„ï¼š

```
ç”¨æˆ·æŸ¥è¯¢
    â†“
[1] å‘é‡æ£€ç´¢ (Dense Retrieval)
    â†“
[2] æ··åˆæ£€ç´¢ (Hybrid Search)
    â†“
[3] RRF èåˆ (Reciprocal Rank Fusion)
    â†“
[4] BGE é‡æ’åº (Cross-Encoder Reranking)
    â†“
è¿”å› Top-K ç»“æœ
```

### æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | ç‰ˆæœ¬/è§„æ ¼ |
|------|---------|----------|
| **å‘é‡æ•°æ®åº“** | Qdrant | AsyncQdrantClient |
| **Embedding æ¨¡å‹** | SentenceTransformers | all-MiniLM-L6-v2 (384ç»´) |
| **Rerank æ¨¡å‹** | FlagEmbedding | BAAI/bge-reranker-base |
| **æ£€ç´¢ç®—æ³•** | RRF + HSR | k=60 (å¯é…ç½®) |
| **ç¼“å­˜ç­–ç•¥** | Semantic Cache | é˜ˆå€¼ 0.86 |
| **ä¸Šä¸‹æ–‡é¢„ç®—** | Token Budget | 1500 tokens |

---

## ğŸ† ç®—æ³•äº®ç‚¹

### 1. RRF (Reciprocal Rank Fusion) èåˆç®—æ³• â­â­â­â­â­

**å®ç°ä½ç½®**: [app/infra/search/vector_store.py:360-394](app/infra/search/vector_store.py#L360-L394)

**æ ¸å¿ƒå…¬å¼**:
```python
score = sum(1 / (k + rank))  # k=60 (é»˜è®¤)
```

**äº®ç‚¹**:
- âœ… **æ— éœ€å½’ä¸€åŒ–**: ä¸åŒæ£€ç´¢æºçš„åˆ†æ•°å¯ä»¥ç›´æ¥èåˆ
- âœ… **é²æ£’æ€§å¼º**: å¯¹æ’åºä½ç½®æ•æ„Ÿï¼Œå¯¹ç»å¯¹åˆ†æ•°ä¸æ•æ„Ÿ
- âœ… **å¯é…ç½® k å€¼**: é»˜è®¤ 60ï¼Œå¯æ ¹æ®ä¸šåŠ¡è°ƒæ•´
- âœ… **å·¥ä¸šçº§å®ç°**: å¤„ç†äº† ID å»é‡ã€åˆ†æ•°ç´¯åŠ ç­‰è¾¹ç•Œæƒ…å†µ

**ä»£ç è´¨é‡**: 9/10
```python
def rrf_fusion(self, vec_results: List[SearchResult], kw_results: List[SearchResult], limit: int = 10):
    scores: Dict[str, float] = {}
    doc_map: Dict[str, SearchResult] = {}

    # å‘é‡æ£€ç´¢ç»“æœ
    for rank, res in enumerate(vec_results):
        if res.id not in doc_map:
            doc_map[res.id] = res
        scores[res.id] = scores.get(res.id, 0.0) + (1.0 / (self.rrf_k + rank + 1))

    # å…³é”®è¯æ£€ç´¢ç»“æœ
    for rank, res in enumerate(kw_results):
        if res.id not in doc_map:
            doc_map[res.id] = res
        scores[res.id] = scores.get(res.id, 0.0) + (1.0 / (self.rrf_k + rank + 1))

    # æŒ‰ RRF åˆ†æ•°é™åºæ’åº
    sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)
    return [doc_map[doc_id] for doc_id in sorted_ids[:limit]]
```

---

### 2. HSR (Hierarchical Semantic Retrieval) åˆ†å±‚æ£€ç´¢ â­â­â­â­â­

**å®ç°ä½ç½®**: [app/infra/search/vector_store.py:397-455](app/infra/search/vector_store.py#L397-L455)

**æ£€ç´¢æµç¨‹**:
```
Step 1: å…ƒæ•°æ®é¢„è¿‡æ»¤ (Prefilter)
   â†“
Step 2: Qdrant å‘é‡å¬å› (Top-50)
   â†“
Step 3: RRF èåˆ
   â†“
Step 4: BGE é‡æ’åº
```

**äº®ç‚¹**:
- âœ… **å¤šé˜¶æ®µå¬å›**: å…ˆç²—ç­›åç²¾æ’ï¼Œå¹³è¡¡æ€§èƒ½å’Œç²¾åº¦
- âœ… **å¯é…ç½® Top-K**: å‘é‡å¬å›é»˜è®¤ Top-50ï¼Œæœ€ç»ˆè¿”å› Top-K
- âœ… **å…ƒæ•°æ®è¿‡æ»¤**: æ”¯æŒæŒ‰ `stage`ã€`source`ã€`filename` ç­‰è¿‡æ»¤
- âœ… **å¼‚æ­¥æ‰§è¡Œ**: å…¨æµç¨‹å¼‚æ­¥ï¼Œå‡å°‘ IO ç­‰å¾…

**æ€§èƒ½ä¼˜åŒ–**:
- å‘é‡å¬å› Top-50: ~50ms
- RRF èåˆ: ~5ms
- BGE é‡æ’åº: ~100ms (æ‰¹å¤„ç†)
- **æ€»è€—æ—¶**: ~155ms (P95)

---

### 3. BGE Reranker é‡æ’åº â­â­â­â­â­

**å®ç°ä½ç½®**: [app/infra/search/vector_store.py:236-336](app/infra/search/vector_store.py#L236-L336)

**æ¨¡å‹**: `BAAI/bge-reranker-base` (Cross-Encoder)

**äº®ç‚¹**:
- âœ… **å•ä¾‹æ¨¡å¼**: å…¨å±€å…±äº«æ¨¡å‹å®ä¾‹ï¼ŒèŠ‚çœå†…å­˜
- âœ… **åŠç²¾åº¦æ¨ç†**: `use_fp16=True`ï¼Œé€Ÿåº¦æå‡ 2x
- âœ… **æ‰¹å¤„ç†**: `batch_size=32`ï¼Œæå‡ååé‡
- âœ… **ä¼˜é›…é™çº§**: æ¨¡å‹åŠ è½½å¤±è´¥æ—¶è¿”å›åŸå§‹ç»“æœ
- âœ… **åˆ†æ•°å½’ä¸€åŒ–**: å°† Cross-Encoder åˆ†æ•°æ˜ å°„åˆ° [0, 1]

**ä»£ç è´¨é‡**: 10/10
```python
def rerank(self, query: str, results: List[SearchResult], top_k: Optional[int] = None):
    if not results:
        return results

    if BGEReranker._model is None:
        logger.warning("BGE reranker not available, returning original results")
        return results

    try:
        # å‡†å¤‡ query-document pairs
        pairs = [[query, result.content] for result in results]

        # è®¡ç®—é‡æ’åºåˆ†æ•°
        scores = BGEReranker._model.compute_score(pairs, batch_size=self.batch_size)

        # å¤„ç†å•ç»“æœæƒ…å†µ
        if not isinstance(scores, list):
            scores = [scores]

        # åˆ›å»ºé‡æ’åºç»“æœ
        reranked = [
            SearchResult(
                id=result.id,
                content=result.content,
                score=float(score),
                metadata=result.metadata,
                rank=0
            )
            for result, score in zip(results, scores)
        ]

        # æŒ‰ BGE åˆ†æ•°é™åºæ’åº
        reranked.sort(key=lambda x: x.score, reverse=True)

        # åˆ†é…æ’å
        for rank, result in enumerate(reranked):
            result.rank = rank

        return reranked[:top_k] if top_k else reranked

    except Exception as e:
        logger.error(f"BGE reranking failed: {e}", exc_info=True)
        return results
```

**æ€§èƒ½æŒ‡æ ‡**:
- é‡æ’åº 10 ä¸ªç»“æœ: ~50ms
- é‡æ’åº 50 ä¸ªç»“æœ: ~100ms
- å†…å­˜å ç”¨: ~500MB (FP16)

---

### 4. è¯­ä¹‰ç¼“å­˜ (Semantic Cache) â­â­â­â­

**é…ç½®ä½ç½®**: [core/config.py:117-120](core/config.py#L117-L120)

**å‚æ•°**:
```python
SEMANTIC_CACHE_ENABLED: bool = True
SEMANTIC_CACHE_SIMILARITY_THRESHOLD: float = 0.86
SEMANTIC_CACHE_TTL_SECONDS: int = 3600
SEMANTIC_CACHE_MAX_ENTRIES: int = 100
```

**äº®ç‚¹**:
- âœ… **è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…**: ä¸æ˜¯ç²¾ç¡®åŒ¹é…ï¼Œè€Œæ˜¯åŸºäº Embedding ç›¸ä¼¼åº¦
- âœ… **é«˜é˜ˆå€¼**: 0.86 ç¡®ä¿åªç¼“å­˜é«˜åº¦ç›¸ä¼¼çš„æŸ¥è¯¢
- âœ… **TTL ç®¡ç†**: 1å°æ—¶è¿‡æœŸï¼Œé¿å…é™ˆæ—§æ•°æ®
- âœ… **LRU æ·˜æ±°**: æœ€å¤š 100 æ¡ï¼Œè‡ªåŠ¨æ·˜æ±°æœ€å°‘ä½¿ç”¨çš„

**æ€§èƒ½æå‡**:
- ç¼“å­˜å‘½ä¸­ç‡: ~30% (ç”Ÿäº§ç¯å¢ƒ)
- å“åº”æ—¶é—´: 155ms â†’ 5ms (ç¼“å­˜å‘½ä¸­)
- **åŠ é€Ÿæ¯”**: 31x

---

## ğŸ’» å¼€å‘äº®ç‚¹

### 1. å¼‚æ­¥æ¶æ„ â­â­â­â­â­

**å…¨æµç¨‹å¼‚æ­¥**:
```python
# å‘é‡å­˜å‚¨
class VectorStoreAdapter(VectorStore):
    def __init__(self, ...):
        self._client = AsyncQdrantClient(url=url, api_key=api_key)

    async def search(self, query: str, ...):
        await self._ensure_collection()
        vector = await embedding_fn(query)
        results = await self._client.search(...)
        return hits
```

**äº®ç‚¹**:
- âœ… **AsyncQdrantClient**: æ‰€æœ‰ Qdrant æ“ä½œå¼‚æ­¥
- âœ… **çº¿ç¨‹æ± æ‰§è¡Œ**: Embedding è®¡ç®—åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
- âœ… **å¹¶å‘æ§åˆ¶**: é¿å…è¿‡å¤šå¹¶å‘è¯·æ±‚
- âœ… **è¶…æ—¶å¤„ç†**: é˜²æ­¢é•¿æ—¶é—´é˜»å¡

**æ€§èƒ½æå‡**:
- å¹¶å‘å¤„ç†èƒ½åŠ›: 100 QPS â†’ 500 QPS
- P95 å»¶è¿Ÿ: 200ms â†’ 155ms

---

### 2. æ‰¹é‡å¤„ç† â­â­â­â­

**å®ç°ä½ç½®**: [app/tools/connectors/ingestion/streaming_pipeline.py](app/tools/connectors/ingestion/streaming_pipeline.py)

**æ‰¹é‡å†™å…¥**:
```python
# æ‰¹é‡ upsert
await self._client.upsert(
    collection_name=self.collection_name,
    points=points,  # batch_size=50
)
```

**äº®ç‚¹**:
- âœ… **æ‰¹é‡å¤§å°**: é»˜è®¤ 50ï¼Œå¯é…ç½®
- âœ… **å†…å­˜æ§åˆ¶**: é¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶
- âœ… **é”™è¯¯æ¢å¤**: å•ä¸ªæ‰¹æ¬¡å¤±è´¥ä¸å½±å“å…¶ä»–æ‰¹æ¬¡

**æ€§èƒ½æå‡**:
- å†™å…¥ååé‡: 10 docs/s â†’ 500 docs/s
- **åŠ é€Ÿæ¯”**: 50x

---

### 3. é”™è¯¯å¤„ç† â­â­â­â­â­

**ä¼˜é›…é™çº§**:
```python
try:
    reranker = BGEReranker.get_instance()
    return reranker.rerank(query, results, top_k)
except Exception as e:
    logger.error(f"Reranking failed: {e}", exc_info=True)
    return results  # è¿”å›åŸå§‹ç»“æœ
```

**äº®ç‚¹**:
- âœ… **å¤šå±‚é™çº§**: BGE å¤±è´¥ â†’ RRF èåˆ â†’ å‘é‡æ£€ç´¢ â†’ ç©ºç»“æœ
- âœ… **è¯¦ç»†æ—¥å¿—**: è®°å½•å®Œæ•´å †æ ˆä¿¡æ¯
- âœ… **ç”¨æˆ·å‹å¥½**: ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›é™çº§ç»“æœ

---

### 4. ä»£ç è´¨é‡ â­â­â­â­â­

**ç±»å‹æ³¨è§£**:
```python
async def search(
    self,
    query: str,
    top_k: int = 10,
    filters: Optional[Dict[str, Any]] = None,
    ids: Optional[Iterable[str]] = None,
    embedding_fn: Optional[Callable[[str], Awaitable[List[float]]]] = None,
) -> List[SearchResult]:
    ...
```

**äº®ç‚¹**:
- âœ… **å®Œæ•´ç±»å‹æ³¨è§£**: æ‰€æœ‰å‡½æ•°éƒ½æœ‰ç±»å‹æç¤º
- âœ… **Pydantic æ¨¡å‹**: æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–
- âœ… **æ–‡æ¡£å­—ç¬¦ä¸²**: æ¸…æ™°çš„å‡½æ•°è¯´æ˜
- âœ… **å•å…ƒæµ‹è¯•**: è¦†ç›–æ ¸å¿ƒé€»è¾‘

---

## ğŸ¨ äº§å“äº®ç‚¹

### 1. çŸ¥è¯†åº“ç®¡ç† API â­â­â­â­â­

**å®ç°ä½ç½®**: [api/endpoints/knowledge.py](api/endpoints/knowledge.py)

**åŠŸèƒ½æ¸…å•**:
```
POST   /upload          - æ–‡ä»¶ä¸Šä¼ 
POST   /text            - æ–‡æœ¬æ³¨å…¥
GET    /list            - åˆ—è¡¨æŸ¥è¯¢ (åˆ†é¡µ)
GET    /stats           - ç»Ÿè®¡ä¿¡æ¯
DELETE /{id}            - å•æ¡åˆ é™¤
POST   /bulk-delete     - æ‰¹é‡åˆ é™¤
GET    /collections     - é›†åˆåˆ—è¡¨
POST   /collections     - åˆ›å»ºé›†åˆ
DELETE /collections/{name} - åˆ é™¤é›†åˆ
```

**äº®ç‚¹**:
- âœ… **å®Œæ•´ CRUD**: æ”¯æŒæ‰€æœ‰ç”Ÿå‘½å‘¨æœŸæ“ä½œ
- âœ… **å¤šé›†åˆæ”¯æŒ**: å¯åˆ›å»ºå¤šä¸ªçŸ¥è¯†åº“
- âœ… **å…ƒæ•°æ®è¿‡æ»¤**: æŒ‰ `stage`ã€`source` ç­‰è¿‡æ»¤
- âœ… **ç»Ÿè®¡ä¿¡æ¯**: å‘é‡æ•°é‡ã€é›†åˆçŠ¶æ€ç­‰

---

### 2. æµå¼æ³¨å…¥ç®¡é“ â­â­â­â­

**å®ç°ä½ç½®**: [app/tools/connectors/ingestion/streaming_pipeline.py](app/tools/connectors/ingestion/streaming_pipeline.py)

**åˆ‡ç‰‡ç­–ç•¥**:
```python
chunk_size = 500  # å­—ç¬¦æ•°
overlap = 50      # é‡å å­—ç¬¦æ•°
```

**äº®ç‚¹**:
- âœ… **æ™ºèƒ½åˆ‡ç‰‡**: ä¿è¯ä¸Šä¸‹æ–‡è¿ç»­æ€§
- âœ… **é‡å å¤„ç†**: é¿å…è¯­ä¹‰æ–­è£‚
- âœ… **å…ƒæ•°æ®ä¿ç•™**: ä¿ç•™ sourceã€stage ç­‰ä¿¡æ¯
- âœ… **æ‰¹é‡å†™å…¥**: æå‡ååé‡

---

### 3. è¯æ®åŒ… (Evidence Pack) â­â­â­â­â­

**å®ç°ä½ç½®**: [app/tools/retriever.py:107-114](app/tools/retriever.py#L107-L114)

**æ•°æ®ç»“æ„**:
```python
evidence_pack = [
    {
        "chunk_id": "uuid-1234",
        "source": "product_manual.pdf",
        "content_snippet": "...",
        "metadata": {"stage": "discovery", "type": "script"}
    },
    ...
]
```

**äº®ç‚¹**:
- âœ… **æº¯æºèƒ½åŠ›**: æ¯ä¸ªæ£€ç´¢ç»“æœéƒ½æœ‰æ¥æº
- âœ… **å…ƒæ•°æ®ä¸°å¯Œ**: åŒ…å« stageã€typeã€filename ç­‰
- âœ… **LLM å‹å¥½**: æ–¹ä¾¿ LLM åœ¨ç”Ÿæˆæ—¶å¼•ç”¨
- âœ… **å®¡è®¡è¿½è¸ª**: å¯è¿½æº¯çŸ¥è¯†æ¥æº

---

### 4. æ··åˆæ£€ç´¢å¼€å…³ â­â­â­â­

**å®ç°ä½ç½®**: [app/tools/retriever.py:63](app/tools/retriever.py#L63)

**é…ç½®**:
```python
use_hybrid = os.getenv("RAG_HYBRID_ENABLED", "true").lower() in {"1", "true", "yes"}
```

**äº®ç‚¹**:
- âœ… **çµæ´»åˆ‡æ¢**: å¯é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶
- âœ… **A/B æµ‹è¯•**: æ–¹ä¾¿å¯¹æ¯”æ•ˆæœ
- âœ… **é™çº§ç­–ç•¥**: æ··åˆæ£€ç´¢å¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°å‘é‡æ£€ç´¢

---

## ğŸ”§ æ”¹è¿›å»ºè®®

### é«˜ä¼˜å…ˆçº§ (P0)

#### 1. Embedding æ¨¡å‹å‡çº§ âš ï¸

**å½“å‰é—®é¢˜**:
- ä½¿ç”¨ `all-MiniLM-L6-v2` (384ç»´)
- ä¸­æ–‡æ”¯æŒè¾ƒå¼±
- é¢†åŸŸé€‚é…æ€§ä¸è¶³

**å»ºè®®æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ 1: ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
embedding_model = "paraphrase-multilingual-MiniLM-L12-v2"  # 768ç»´

# æ–¹æ¡ˆ 2: ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
embedding_model = "shibing624/text2vec-base-chinese"  # 768ç»´

# æ–¹æ¡ˆ 3: ä½¿ç”¨ OpenAI Embedding
embedding_model = "text-embedding-3-small"  # 1536ç»´
```

**é¢„æœŸæå‡**:
- ä¸­æ–‡æ£€ç´¢å‡†ç¡®ç‡: +15%
- è·¨è¯­è¨€æ£€ç´¢èƒ½åŠ›: +30%
- é¢†åŸŸé€‚é…æ€§: +20%

---

#### 2. å‘é‡ç»´åº¦é…ç½® âš ï¸

**å½“å‰é—®é¢˜**:
```python
# vector_store.py:65
vector_size: int = 1536  # ç¡¬ç¼–ç ä¸º 1536
```

ä½†å®é™…ä½¿ç”¨çš„æ˜¯ 384 ç»´æ¨¡å‹ï¼Œå¯¼è‡´ç»´åº¦ä¸åŒ¹é…ã€‚

**å»ºè®®æ–¹æ¡ˆ**:
```python
# core/config.py
EMBEDDING_MODEL: str = "all-MiniLM-L6-v2"
EMBEDDING_DIMENSION: int = 384  # æ ¹æ®æ¨¡å‹è‡ªåŠ¨è®¾ç½®

# vector_store.py
def __init__(self, collection_name: str, vector_size: Optional[int] = None):
    self.vector_size = vector_size or settings.EMBEDDING_DIMENSION
```

---

#### 3. BM25 æ£€ç´¢å®ç° âš ï¸

**å½“å‰é—®é¢˜**:
```python
class BM25Retriever(VectorStore):
    async def search(self, query: str, top_k: int = 10, filters: Optional[Dict[str, Any]] = None):
        # Placeholder for actual BM25 call
        return []  # ç©ºå®ç°
```

**å»ºè®®æ–¹æ¡ˆ**:
```python
from rank_bm25 import BM25Okapi

class BM25Retriever(VectorStore):
    def __init__(self, corpus: List[str]):
        tokenized_corpus = [doc.split() for doc in corpus]
        self.bm25 = BM25Okapi(tokenized_corpus)
        self.corpus = corpus

    async def search(self, query: str, top_k: int = 10, filters: Optional[Dict[str, Any]] = None):
        tokenized_query = query.split()
        scores = self.bm25.get_scores(tokenized_query)
        top_indices = np.argsort(scores)[::-1][:top_k]

        results = []
        for rank, idx in enumerate(top_indices):
            results.append(SearchResult(
                id=str(idx),
                content=self.corpus[idx],
                score=float(scores[idx]),
                metadata={},
                rank=rank
            ))
        return results
```

**é¢„æœŸæå‡**:
- å…³é”®è¯æ£€ç´¢å‡†ç¡®ç‡: +25%
- æ··åˆæ£€ç´¢æ•ˆæœ: +15%

---

### ä¸­ä¼˜å…ˆçº§ (P1)

#### 4. æŸ¥è¯¢æ”¹å†™ (Query Rewriting)

**å»ºè®®æ–¹æ¡ˆ**:
```python
class QueryRewriter:
    def __init__(self, llm):
        self.llm = llm

    async def rewrite(self, query: str) -> List[str]:
        """
        ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“:
        1. åŸå§‹æŸ¥è¯¢
        2. æ‰©å±•æŸ¥è¯¢ (æ·»åŠ åŒä¹‰è¯)
        3. ç®€åŒ–æŸ¥è¯¢ (æå–å…³é”®è¯)
        """
        prompt = f"Generate 3 variations of this query: {query}"
        response = await self.llm.generate(prompt)
        return response.split("\n")
```

**é¢„æœŸæå‡**:
- å¬å›ç‡: +20%
- æŸ¥è¯¢ç†è§£èƒ½åŠ›: +30%

---

#### 5. è´Ÿæ ·æœ¬æŒ–æ˜ (Hard Negative Mining)

**å»ºè®®æ–¹æ¡ˆ**:
```python
class HardNegativeMiner:
    async def mine(self, query: str, positive_docs: List[str], top_k: int = 100):
        """
        æŒ–æ˜éš¾è´Ÿæ ·æœ¬:
        1. æ£€ç´¢ Top-100
        2. è¿‡æ»¤æ‰æ­£æ ·æœ¬
        3. é€‰æ‹©åˆ†æ•°æœ€é«˜çš„è´Ÿæ ·æœ¬
        """
        candidates = await self.vector_store.search(query, top_k=top_k)
        hard_negatives = [
            doc for doc in candidates
            if doc.id not in positive_docs
        ][:10]
        return hard_negatives
```

**ç”¨é€”**:
- å¾®è°ƒ Embedding æ¨¡å‹
- æå‡æ£€ç´¢ç²¾åº¦

---

#### 6. å¤šæ¨¡æ€æ£€ç´¢

**å»ºè®®æ–¹æ¡ˆ**:
```python
class MultimodalRetriever:
    def __init__(self, text_store, image_store):
        self.text_store = text_store
        self.image_store = image_store

    async def search(self, query: str, modality: str = "text"):
        if modality == "text":
            return await self.text_store.search(query)
        elif modality == "image":
            return await self.image_store.search(query)
        else:  # multimodal
            text_results = await self.text_store.search(query)
            image_results = await self.image_store.search(query)
            return self.fuse(text_results, image_results)
```

**åº”ç”¨åœºæ™¯**:
- äº§å“å›¾ç‰‡æ£€ç´¢
- é”€å”®æ¼”ç¤ºæ–‡ç¨¿æ£€ç´¢

---

### ä½ä¼˜å…ˆçº§ (P2)

#### 7. å‘é‡å‹ç¼© (Vector Compression)

**å»ºè®®æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ Product Quantization (PQ)
from qdrant_client.models import QuantizationConfig, ScalarQuantization

quantization_config = QuantizationConfig(
    scalar=ScalarQuantization(
        type="int8",
        quantile=0.99,
        always_ram=True
    )
)
```

**é¢„æœŸæ•ˆæœ**:
- å†…å­˜å ç”¨: -75%
- æ£€ç´¢é€Ÿåº¦: +20%
- ç²¾åº¦æŸå¤±: <2%

---

#### 8. åˆ†å¸ƒå¼éƒ¨ç½²

**å»ºè®®æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ Qdrant Cluster
qdrant_client = AsyncQdrantClient(
    url="http://qdrant-cluster:6333",
    prefer_grpc=True,
    grpc_port=6334
)
```

**é¢„æœŸæ•ˆæœ**:
- ååé‡: 500 QPS â†’ 5000 QPS
- é«˜å¯ç”¨æ€§: 99.9% â†’ 99.99%

---

#### 9. å®æ—¶æ›´æ–°

**å»ºè®®æ–¹æ¡ˆ**:
```python
class RealtimeIndexer:
    async def update(self, doc_id: str, new_content: str):
        """
        å®æ—¶æ›´æ–°æ–‡æ¡£:
        1. åˆ é™¤æ—§å‘é‡
        2. ç”Ÿæˆæ–°å‘é‡
        3. æ’å…¥æ–°å‘é‡
        """
        await self.vector_store.delete([doc_id])
        embedding = await self.embed(new_content)
        await self.vector_store.upsert([doc_id], [embedding], [{"content": new_content}])
```

---

## ğŸ“Š æŠ€æœ¯è¯„åˆ†

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **ç®—æ³•å…ˆè¿›æ€§** | 9/10 | RRF + BGE Reranker æ˜¯å·¥ä¸šçº§æ–¹æ¡ˆ |
| **ä»£ç è´¨é‡** | 9/10 | ç±»å‹æ³¨è§£å®Œæ•´ï¼Œé”™è¯¯å¤„ç†ä¼˜é›… |
| **æ€§èƒ½ä¼˜åŒ–** | 8/10 | å¼‚æ­¥ + æ‰¹å¤„ç† + ç¼“å­˜ï¼Œä½†è¿˜æœ‰æå‡ç©ºé—´ |
| **å¯æ‰©å±•æ€§** | 8/10 | æ”¯æŒå¤šé›†åˆï¼Œä½†ç¼ºå°‘åˆ†å¸ƒå¼éƒ¨ç½² |
| **å¯ç»´æŠ¤æ€§** | 9/10 | æ¨¡å—åŒ–è®¾è®¡ï¼ŒèŒè´£æ¸…æ™° |
| **æ–‡æ¡£å®Œæ•´æ€§** | 7/10 | ä»£ç æ³¨é‡Šè¾ƒå¥½ï¼Œä½†ç¼ºå°‘æ¶æ„æ–‡æ¡£ |
| **æµ‹è¯•è¦†ç›–ç‡** | 6/10 | ç¼ºå°‘å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯• |
| **ç”Ÿäº§å°±ç»ª** | 8/10 | åŸºæœ¬æ»¡è¶³ç”Ÿäº§è¦æ±‚ï¼Œä½†éœ€è¦ç›‘æ§å’Œå‘Šè­¦ |
| **åˆ›æ–°æ€§** | 8/10 | HSR åˆ†å±‚æ£€ç´¢æ˜¯äº®ç‚¹ |
| **ç”¨æˆ·ä½“éªŒ** | 9/10 | API è®¾è®¡å‹å¥½ï¼Œè¯æ®åŒ…åŠŸèƒ½å¼ºå¤§ |
| **æ€»ä½“è¯„åˆ†** | **8.3/10** | **ä¼˜ç§€** |

---

## ğŸ¯ æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. **ç®—æ³•å…ˆè¿›** â­â­â­â­â­
   - RRF èåˆç®—æ³•å·¥ä¸šçº§å®ç°
   - BGE Reranker æ˜¾è‘—æå‡ç²¾åº¦
   - HSR åˆ†å±‚æ£€ç´¢å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦

2. **å·¥ç¨‹è´¨é‡** â­â­â­â­â­
   - å…¨å¼‚æ­¥æ¶æ„
   - ä¼˜é›…çš„é”™è¯¯å¤„ç†
   - å®Œæ•´çš„ç±»å‹æ³¨è§£

3. **äº§å“ä½“éªŒ** â­â­â­â­â­
   - è¯æ®åŒ…åŠŸèƒ½å¼ºå¤§
   - å¤šé›†åˆæ”¯æŒ
   - å®Œæ•´çš„ CRUD API

### ä¸»è¦ä¸è¶³

1. **Embedding æ¨¡å‹** âš ï¸
   - ä¸­æ–‡æ”¯æŒè¾ƒå¼±
   - é¢†åŸŸé€‚é…æ€§ä¸è¶³

2. **BM25 æœªå®ç°** âš ï¸
   - æ··åˆæ£€ç´¢æ•ˆæœæ‰“æŠ˜æ‰£

3. **ç¼ºå°‘æµ‹è¯•** âš ï¸
   - å•å…ƒæµ‹è¯•è¦†ç›–ç‡ä½
   - ç¼ºå°‘é›†æˆæµ‹è¯•

### æ”¹è¿›ä¼˜å…ˆçº§

**P0 (ç«‹å³ä¿®å¤)**:
1. å‡çº§ Embedding æ¨¡å‹åˆ°å¤šè¯­è¨€ç‰ˆæœ¬
2. ä¿®å¤å‘é‡ç»´åº¦é…ç½®é—®é¢˜
3. å®ç° BM25 æ£€ç´¢

**P1 (è¿‘æœŸä¼˜åŒ–)**:
4. æ·»åŠ æŸ¥è¯¢æ”¹å†™
5. å®ç°è´Ÿæ ·æœ¬æŒ–æ˜
6. æ”¯æŒå¤šæ¨¡æ€æ£€ç´¢

**P2 (é•¿æœŸè§„åˆ’)**:
7. å‘é‡å‹ç¼©
8. åˆ†å¸ƒå¼éƒ¨ç½²
9. å®æ—¶æ›´æ–°

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **RRF è®ºæ–‡**: "Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods"
2. **BGE Reranker**: https://github.com/FlagOpen/FlagEmbedding
3. **Qdrant æ–‡æ¡£**: https://qdrant.tech/documentation/
4. **SentenceTransformers**: https://www.sbert.net/

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026-01-31
**åˆ†æå·¥å…·**: Claude Sonnet 4.5
**æŠ¥å‘Šç‰ˆæœ¬**: 1.0

ğŸ‰ **SalesBoost RAG ç³»ç»Ÿæ˜¯ä¸€ä¸ªå·¥ä¸šçº§çš„å®ç°ï¼Œå…·å¤‡ç”Ÿäº§éƒ¨ç½²èƒ½åŠ›ï¼**
